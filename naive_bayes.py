<<<<<<< HEAD
# # -*- coding: utf-8 -*-
# """Naive Bayes.ipynb

# Automatically generated by Colab.

# Original file is located at
#     https://colab.research.google.com/drive/10gfyDngn5OOlPNO1kLPxQ8j0yZiX_tvC
# """

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve
)
import matplotlib.pyplot as plt

# Load dataset
ecomm_data = pd.read_csv('Cleaned_E_Commerce_Data.csv')

# Data Cleaning
ecomm_data_cleaned = ecomm_data.drop(columns=['CustomerID'])
for column in ecomm_data_cleaned.select_dtypes(include=['float64']).columns:
    ecomm_data_cleaned[column] = ecomm_data_cleaned[column].fillna(ecomm_data_cleaned[column].median())

# Encode categorical variables
categorical_columns = ecomm_data_cleaned.select_dtypes(include=['object']).columns
for column in categorical_columns:
    le = LabelEncoder()
    ecomm_data_cleaned[column] = le.fit_transform(ecomm_data_cleaned[column])

# Select top features based on importance
selected_features = ['Tenure', 'CashbackAmount', 'WarehouseToHome', 'NumberOfAddress', 'DaySinceLastOrder',
                     'Complain', 'OrderAmountHikeFromlastYear', 'SatisfactionScore']
X = ecomm_data_cleaned[selected_features]
y = ecomm_data_cleaned['Churn']

# Scale features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Split data
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42, stratify=y)

# Train Naive Bayes Model
nb_model = GaussianNB()
nb_model.fit(X_train, y_train)

# Predictions
y_pred = nb_model.predict(X_test)
y_pred_proba = nb_model.predict_proba(X_test)[:, 1]

# Calculate metrics
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)
roc_auc = roc_auc_score(y_test, y_pred_proba)

# Plot AUC-ROC Curve
fpr, tpr, _ = roc_curve(y_test, y_pred_proba)
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, label=f'AUC = {roc_auc:.2f}')
plt.plot([0, 1], [0, 1], 'r--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('AUC-ROC Curve')
plt.legend()
plt.show()

# Print metrics
print(f'Accuracy: {accuracy:.4f}')
print(f'Precision: {precision:.4f}')
print(f'Recall: {recall:.4f}')
print(f'F1-Score: {f1:.4f}')
=======
# # -*- coding: utf-8 -*-
# """Naive Bayes.ipynb

# Automatically generated by Colab.

# Original file is located at
#     https://colab.research.google.com/drive/10gfyDngn5OOlPNO1kLPxQ8j0yZiX_tvC
# """

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve
)
import matplotlib.pyplot as plt

# Load dataset
ecomm_data = pd.read_csv('Cleaned_E_Commerce_Data.csv')

# Data Cleaning
ecomm_data_cleaned = ecomm_data.drop(columns=['CustomerID'])
for column in ecomm_data_cleaned.select_dtypes(include=['float64']).columns:
    ecomm_data_cleaned[column] = ecomm_data_cleaned[column].fillna(ecomm_data_cleaned[column].median())

# Encode categorical variables
categorical_columns = ecomm_data_cleaned.select_dtypes(include=['object']).columns
for column in categorical_columns:
    le = LabelEncoder()
    ecomm_data_cleaned[column] = le.fit_transform(ecomm_data_cleaned[column])

# Select top features based on importance
selected_features = ['Tenure', 'CashbackAmount', 'WarehouseToHome', 'NumberOfAddress', 'DaySinceLastOrder',
                     'Complain', 'OrderAmountHikeFromlastYear', 'SatisfactionScore']
X = ecomm_data_cleaned[selected_features]
y = ecomm_data_cleaned['Churn']

# Scale features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Split data
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42, stratify=y)

# Train Naive Bayes Model
nb_model = GaussianNB()
nb_model.fit(X_train, y_train)

# Predictions
y_pred = nb_model.predict(X_test)
y_pred_proba = nb_model.predict_proba(X_test)[:, 1]

# Calculate metrics
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)
roc_auc = roc_auc_score(y_test, y_pred_proba)

# Plot AUC-ROC Curve
fpr, tpr, _ = roc_curve(y_test, y_pred_proba)
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, label=f'AUC = {roc_auc:.2f}')
plt.plot([0, 1], [0, 1], 'r--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('AUC-ROC Curve')
plt.legend()
plt.show()

# Print metrics
print(f'Accuracy: {accuracy:.4f}')
print(f'Precision: {precision:.4f}')
print(f'Recall: {recall:.4f}')
print(f'F1-Score: {f1:.4f}')
>>>>>>> 6beea00e2bacdf6a04b11b2a917af4c0134bb444
print(f'AUC-ROC: {roc_auc:.4f}')